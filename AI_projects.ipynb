{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4g25asGw9/m0gZQKdw+BW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saikumar7952/AI/blob/main/AI_projects.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0SX4GtiRC4uv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Giving input**"
      ],
      "metadata": {
        "id": "tI--MFNKC6A_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gensim nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I274LUxGxEDn",
        "outputId": "54a60bb6-0a86-48fa-8c13-da929a0df8b9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "documents = [\n",
        "    'The stock market is showing a downward trend in tech companies.',\n",
        "    'A new political debate is scheduled for next week.',\n",
        "    'Football players are preparing for the upcoming season.',\n",
        "    'Technology innovations are changing how we live.',\n",
        "    'The government will discuss new policies next month.'\n",
        "]\n",
        "stop_words = stopwords.words('english')\n",
        "texts = [\n",
        "    [word for word in doc.lower().split() if word not in stop_words]\n",
        "    for doc in documents\n",
        "]\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "lda = LdaModel(corpus, num_topics=2, id2word=dictionary, passes=15)\n",
        "topics = lda.print_topics(num_words=4)\n",
        "for topic in topics:\n",
        "    print(topic)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJziVp49xP6A",
        "outputId": "8d9dbd3c-4153-4bed-e42f-d929c76d460e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '0.083*\"new\" + 0.083*\"next\" + 0.050*\"discuss\" + 0.050*\"government\"')\n",
            "(1, '0.062*\"stock\" + 0.062*\"trend\" + 0.062*\"market\" + 0.062*\"showing\"')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***USING DATASET***\n"
      ],
      "metadata": {
        "id": "RRxg0Jky8wxY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract text from the uploaded document so that you can analyze it.\n",
        "For PDF: Use libraries like PyPDF2 or pdfplumber.\n",
        "For DOCX: Use python-docx.\n",
        "For PPT: Use python-pptx.\n"
      ],
      "metadata": {
        "id": "x7-A5IOg9D8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pdfplumber\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4rPC5Rp89dG",
        "outputId": "ac087cc8-ebc9-4448-e4fc-646c784a010d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20231228 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.1.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Downloading pdfplumber-0.11.5-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.5 pypdfium2-4.30.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To extract text from a PDF:"
      ],
      "metadata": {
        "id": "impye7459N3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        text = \"\"\n",
        "        for page in pdf.pages:\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "text = extract_text_from_pdf(\"pitchdeck.pdf\")\n",
        "text\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "TCBT5eZ99SAL",
        "outputId": "66ed5e83-932b-4bef-a59c-81cbfb9ef454"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'GreenTech Solutions - Pitch Deck\\nIntroduction\\nGreenTech Solutions is an innovative startup dedicated to providing affordable and sustainable solar energy solutions for urban and rural households. Our mission is to reduce dependence on fossil fuels and make clean energy accessible to everyone.\\nProblem\\nTraditional energy sources are expensive, environmentally harmful, and unreliable. Millions of homes and businesses struggle with high electricity costs, frequent power outages, and lack of access to renewable energy alternatives.\\nSolution\\nWe offer a solar-powered energy storage system that reduces electricity costs by 30%, provides backup power during outages, and integrates with smart home technology for energy efficiency. Our modular design allows for scalability based on energy needs.\\nMarket\\n- The global renewable energy market is expected to grow at 20% annually.\\n- The solar energy storage industry is projected to reach $200 billion by 2030.\\n- Our initial target market includes urban homeowners, small businesses, and rural communities with unreliable electricity access.\\nBusiness Model\\n- Direct sales of solar energy storage units to consumers and businesses.\\n- Subscription-based maintenance services for recurring revenue.\\n- Partnerships with real estate developers, government programs, and energy companies.\\nFinancials\\n- Year 1 revenue projection: $1 million.\\n- Break-even point: Expected within 2 years.\\n- Gross profit margin: Estimated at 40%.\\n- Funding requirement: Seeking $500,000 in seed investment to scale production and expand market reach.\\nTeam\\nOur team consists of experienced professionals:\\n- CEO & Founder - 10+ years in renewable energy solutions.\\n- CTO - Expert in solar energy and IoT integrations.\\n- CMO - 8 years in marketing and business growth.\\n- Lead Engineer - Solar energy system designer.- Operations Manager - Logistics and supply chain expert.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text Preprocessing**"
      ],
      "metadata": {
        "id": "WB919Gel_QZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "import re\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
        "    text = text.lower()\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    stemmer = PorterStemmer()\n",
        "    tokens = [stemmer.stem(word) for word in tokens]\n",
        "\n",
        "    return tokens\n",
        "cleaned_text = preprocess_text(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wb-209xI_VPQ",
        "outputId": "fc42353a-19fe-4a67-c8ab-f5db04543fa6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pitch Deck Analysis**"
      ],
      "metadata": {
        "id": "XRw5JEEXBeDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_sections(text):\n",
        "    sections = {\n",
        "        \"Introduction\": \"\",\n",
        "        \"Problem\": \"\",\n",
        "        \"Solution\": \"\",\n",
        "        \"Market\": \"\",\n",
        "        \"Business Model\": \"\",\n",
        "        \"Financials\": \"\",\n",
        "        \"Team\": \"\"\n",
        "    }\n",
        "\n",
        "    text_string = \" \".join(text)\n",
        "    for section in sections:\n",
        "        if section.lower() in text_string.lower():\n",
        "            sections[section] = text_string.split(section)[1].split(\"\\n\")[0]  # Extract text after the keyword\n",
        "    return sections\n",
        "sections = detect_sections(cleaned_text)\n"
      ],
      "metadata": {
        "id": "ka44_ogNBfsI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Section Evaluation:**\n",
        "Evaluate the quality of each section using keyword analysis or sentiment analysis.\n",
        "For example, check if the Problem section clearly describes a pain point.\n"
      ],
      "metadata": {
        "id": "PPJ58T8nCI_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_section(section_text):\n",
        "    if \"problem\" in section_text:\n",
        "        return \"Good job defining the problem!\"\n",
        "    else:\n",
        "        return \"Consider elaborating more on the problem you're solving.\"\n",
        "problem_feedback = evaluate_section(sections[\"Problem\"])\n"
      ],
      "metadata": {
        "id": "JZ4GosMTCMrq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Automated Feedback Generation**"
      ],
      "metadata": {
        "id": "NuZd_yDyCXPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_feedback(sections):\n",
        "    feedback = {}\n",
        "    feedback[\"Problem\"] = evaluate_section(sections[\"Problem\"])\n",
        "    feedback[\"Solution\"] = evaluate_section(sections[\"Solution\"])\n",
        "    feedback[\"Market\"] = evaluate_section(sections[\"Market\"])\n",
        "    feedback[\"Financials\"] = evaluate_section(sections[\"Financials\"])\n",
        "    feedback[\"Team\"] = evaluate_section(sections[\"Team\"])\n",
        "\n",
        "    return feedback\n",
        "feedback = generate_feedback(sections)\n",
        "print(feedback)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlSjhDTlCY86",
        "outputId": "093792a3-1f27-4856-e5b8-93be9604360d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Problem': \"Consider elaborating more on the problem you're solving.\", 'Solution': \"Consider elaborating more on the problem you're solving.\", 'Market': \"Consider elaborating more on the problem you're solving.\", 'Financials': \"Consider elaborating more on the problem you're solving.\", 'Team': \"Consider elaborating more on the problem you're solving.\"}\n"
          ]
        }
      ]
    }
  ]
}